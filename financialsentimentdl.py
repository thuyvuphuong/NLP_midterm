# -*- coding: utf-8 -*-
"""FinancialSentimentDL.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1hM4Pn48KI6J-relffjwYJ6aOkyFNOQg6
"""

import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
import random
import spacy
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras import models

import sklearn
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
from sklearn.metrics import make_scorer, classification_report
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.tree import DecisionTreeClassifier
from sklearn.svm import SVC
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import cross_validate
from sklearn.metrics import confusion_matrix
import seaborn as sn

!python -m spacy download en_core_web_md

nlp = spacy.load("en_core_web_md")

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/drive/MyDrive/Study/NLP

fcommentDF=pd.read_csv('finan.csv')
fcommentDF = fcommentDF[['Sentence','Sentiment']].dropna()

fcommentDF.head()

finan_sentence_exp = []
categories = []

for idx, rw in fcommentDF.iterrows():
    comments = rw["Sentence"]
    rating = rw["Sentiment"]
    mtoks = [token.text for token in nlp(comments)]
    finan_sentence_exp.append(mtoks)

    if rating == 'positive':
        categories.append(1)
    if rating == 'negative':
        categories.append(0)
    if rating == 'neutral':
        categories.append(2)

"""***Get IDs***"""

ktoken = Tokenizer(lower=True)
ktoken.fit_on_texts(finan_sentence_exp)
seq_utterance = ktoken.texts_to_sequences(finan_sentence_exp)

"""***Padding***"""

from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()

MLEN = 32
# Create pad utterance sequence object
ps_utterance = pad_sequences(seq_utterance, MLEN, padding="post")
ps_utterance = np.array(ps_utterance)
ps_utterance_ = scaler.fit_transform(ps_utterance)
catlist = np.array(categories)
catlist = catlist.reshape(catlist.shape[0] , 1)
print(catlist.shape)

"""### **Train-Test Split**

***Splitting into Train and Test set***
"""

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(ps_utterance_, catlist, random_state=1, test_size=0.2, shuffle=True)
y_train = np.reshape(y_train, (y_train.shape[0],))
y_test = np.reshape(y_test, (y_test.shape[0]))

np.unique(y_train, return_counts=True)

print(X_train.shape)
print(X_test.shape)
print(y_train.shape)
print(y_test.shape)

def plot_confusion_matrix(true_label, predict_label, pl = False):
    categories = ['Neural', 'Positive', 'Negative']
    cm = confusion_matrix(y_true = true_label, y_pred = predict_label)
    cm_per = np.round(cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]*100,2)
    if pl == True:
        df_cm = pd.DataFrame(cm_per, index = categories, columns = categories)
        plt.figure(figsize = (6,5))
        sn.heatmap(df_cm, annot=True, cmap = "Blues", linewidths=.1 ,fmt='.2f')
        plt.title("Confusion matrix")
        plt.xlabel('Predict', fontsize=12)
        plt.ylabel('True', fontsize=12)
        plt.tight_layout()

utterance_input = layers.Input(shape=X_train[0].shape)
embedding = layers.Embedding(input_dim = len(ktoken.word_index)+1, output_dim = 100)(utterance_input)
LSTM_layer = layers.LSTM(units=256)(embedding)
outlayer = layers.Dense(128, activation='relu')(LSTM_layer)
outlayer = layers.Dense(64, activation='relu')(outlayer)
outlayer = layers.Dense(1, activation='softmax')(outlayer)
finan_mdl = models.Model(inputs=[utterance_input],outputs=[outlayer])
finan_mdl.summary()

lr = 0.0001
optimizer = tf.keras.optimizers.Adam(learning_rate=lr)
loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False)
metrics = ['accuracy']
finan_mdl.compile(optimizer=optimizer, loss=loss, metrics=metrics)

history = finan_mdl.fit(x=X_train,
                        y=y_train,
                        batch_size=32,
                        epochs=30,
                        validation_split=0.2)

finan_mdl.evaluate(X_test, y_test)

