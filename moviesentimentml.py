# -*- coding: utf-8 -*-
"""MovieSentimentML.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1iQdL2gFInryFVwfRbDTbeWcmrSpx38_7
"""

import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
import random
import spacy
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
import sklearn
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
from sklearn.metrics import make_scorer, classification_report
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.tree import DecisionTreeClassifier
from sklearn.svm import SVC
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import cross_validate
from sklearn.metrics import confusion_matrix
import seaborn as sn

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/drive/MyDrive/Study/NLP

def plot_confusion_matrix(true_label, predict_label, pl = False):
    categories = ['Positive', 'Negative']
    cm = confusion_matrix(y_true = true_label, y_pred = predict_label)
    cm_per = np.round(cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]*100,2)
    if pl == True:
        df_cm = pd.DataFrame(cm_per, index = categories, columns = categories)
        plt.figure(figsize = (5, 4))
        sn.heatmap(df_cm, annot=True, cmap = "Blues", linewidths=.1 ,fmt='.2f')
        plt.title("Confusion matrix")
        plt.xlabel('Predict', fontsize=12)
        plt.ylabel('True', fontsize=12)
        plt.tight_layout()

def model_report(trained_model):
    y_pred = trained_model.predict(X_test)

    accuracy = accuracy_score(y_test, y_pred)
    print(f"Accuracy: {round(accuracy*100, 2)}%")

    classification_report_result = classification_report(y_test, y_pred)
    print(classification_report_result)

    plot_confusion_matrix(y_pred, y_test, pl=True)

"""## **Training Data Preparation**

***Load data***
"""

aug_mcommentDF=pd.read_csv('imdb_preprocessed.csv')
aug_mcommentDF.head()

aug_mcommentDF['concatenated_text'] = aug_mcommentDF['stemmed'].apply(lambda x: ' '.join(eval(x)))

# extract review text and review label from each dataset row and add them into Python lists
movie_comments = []
categories = []
# Perform Tokenization
for idx, rw in aug_mcommentDF.iterrows():
    comments = rw["concatenated_text"]
    sentence = ' '.join(comments)
    rating = rw["Sentiment"]
    categories.append(rating)
    movie_comments.append(comments)

"""## **TF-IDF**"""

tfidf_vectorizer = TfidfVectorizer(ngram_range=(1,3))
data_tfidf = tfidf_vectorizer.fit_transform(movie_comments)

"""***Splitting into Train and Test set***"""

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(data_tfidf, categories, random_state=1, test_size=0.1, shuffle=True)

"""## **Training Models**

***SVM***
"""

clf_SVM = SVC()
clf_SVM.fit(X_train, y_train)

model_report(clf_SVM)

"""***Logistic Classification***"""

clf_LR = LogisticRegression(random_state=0)
clf_LR.fit(X_train, y_train)

model_report(clf_LR)

"""***Random Forest***"""

clf_RF = RandomForestClassifier(max_depth=2, random_state=0)
clf_RF.fit(X_train, y_train)

model_report(clf_RF)

"""***Multinomial Naive Bayes***"""

clf_NB = MultinomialNB()
clf_NB.fit(X_train, y_train)

model_report(clf_NB)

"""## **Cross Validate the best model**"""

scoring = {'accuracy': 'accuracy',
           'precision_macro': make_scorer(precision_score, average='macro'),
           'recall_macro': make_scorer(recall_score, average='macro'),
           'f1_macro': make_scorer(f1_score, average='macro')}

# Perform cross-validation
cv_results = cross_validate(clf_NB, data_tfidf, categories, cv=5, scoring=scoring)

# Calculate and print the average scores
best_accuracy = np.max(cv_results['test_accuracy'])
best_precision = np.max(cv_results['test_precision_macro'])
best_recall = np.max(cv_results['test_recall_macro'])
best_f1 = np.max(cv_results['test_f1_macro'])

print(f"Best Accuracy: {round(best_accuracy * 100, 2)}%")
print(f"Average Precision (Macro): {round(best_precision * 100, 2)}%")
print(f"Average Recall (Macro): {round(best_recall * 100, 2)}%")
print(f"Average F1 Score (Macro): {round(best_f1 * 100, 2)}%")

import numpy as np
import matplotlib.pyplot as plt

def plot_performance(performance):
    N = 4
    ind = np.arange(N)
    width = 0.2

    xvals = performance[0]
    bar1 = plt.bar(ind, xvals, width, edgecolor='black')
    add_labels(bar1)

    yvals = performance[1]
    bar2 = plt.bar(ind+width, yvals, width, edgecolor='black')
    add_labels(bar2)

    zvals = performance[2]
    bar3 = plt.bar(ind+width*2, zvals, width, edgecolor='black')
    add_labels(bar3)

    plt.xlabel("Models")
    plt.ylabel('Evaluation [%]')
    plt.title("Models Evaluation")

    plt.grid(linestyle='--')
    plt.xticks(ind+width,['Precision', 'Recall', 'F1-score', 'Accuracy'])
    plt.legend((bar1, bar2, bar3), ('Logistic Regression', 'Random Forest', 'Multinomial\nNaiveBayes'), loc='lower right')

    plt.show()

def add_labels(bars):
    for bar in bars:
        yval = bar.get_height()
        plt.text(bar.get_x() + bar.get_width() / 2, yval, round(yval, 2), ha='center', va='bottom')

performance = ([89, 88, 88, 88], [67, 66, 65, 66], [89, 89, 89, 88])
plot_performance(performance)

import matplotlib.pyplot as plt

# Data
categories = ['Accuracy', 'Precision', 'Recall', 'F1-Score']
values = [89.16, 89.18, 89.16, 89.16]

# Create a bar chart
plt.figure(figsize=(5, 3.5))
plt.bar(categories, values, edgecolor='black', width=0.5)

# Adding data labels
for i, value in enumerate(values):
    plt.text(i, value + 0.1, f'{value:.2f}%', ha='center', va='bottom')

# Adding title and labels
plt.ylim(0, 100)
plt.title('Performance Metrics of cross validation of Naive Bayes', fontsize=11)
plt.xlabel('Metrics')
plt.ylabel('Percentage')
plt.grid()

# Display the plot
plt.show()